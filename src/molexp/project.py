from hamilton import driver
from hamilton.graph_types import HamiltonGraph
from hamilton.io.materialization import to
from hamilton.experimental.h_cache import CachingGraphAdapter
from hamilton.plugins import h_experiments
from hamilton.function_modifiers import tag, value, parameterize
from hamilton.execution.executors import DefaultExecutionManager, TaskExecutor
from hamilton.execution import executors

import os
from pathlib import Path

from .param import Param, ParamList

class ExperimentTracker(h_experiments.ExperimentTracker):

    def run_before_graph_execution(self, *, graph: HamiltonGraph, inputs: driver.Dict[str, driver.Any], overrides: driver.Dict[str, driver.Any], **kwargs):
        print(f"inputs: {inputs}")
        print(f"init_directory: {self.init_directory}")
        print(f"run_directory: {self.run_directory}")
        super().run_before_graph_execution(graph=graph, inputs=inputs, overrides=overrides, **kwargs)
        # TODO: how to make graph execute in run_directory
        # so output from cmdline execution will be saved in run_directory
        os.chdir(Path(self.run_directory))

    def run_after_graph_execution(self, *, success: bool, **kwargs):
        super().run_after_graph_execution(success=success, **kwargs)
        os.chdir(Path(self.init_directory))

class Project:

    def __init__(self, name: str, work_dir: str | Path = Path.cwd()):
        
        self.name = name
        self.experiments = {}
        self.work_dir = work_dir
        
    def execute(self, param_list: ParamList, final_var, *modules):
        """
        initialize experiments
        """
        tracker_hook = ExperimentTracker(
            experiment_name=self.name,
            base_directory=self.work_dir,
        )

        execution_manager = DefaultExecutionManager(
            executors.SynchronousLocalTaskExecutor(),
            executors.MultiThreadingExecutor(20),
        )
        
        dr = (
            driver.Builder()
            .with_modules(*modules)
            .enable_dynamic_execution(allow_experimental_mode=True)
            .with_execution_manager(execution_manager)
            .with_adapters(tracker_hook)
            .build()
        )
        for param in param_list:  # TODO: parallelize
            self.experiments[param.name] = param
            dr.execute(final_var, inputs={'param': param})

    def list(self):
        """list all experiment"""
        return self.experiments

    def group(self, key: str):
        """group experiments by key, since we need to average the results
        for example:
            input: {'a': 1, 'b': 2, 'id': [1, 2, 3]} # means 3 experiments generated by a=1, b=2
            output: len(project.group('id')) == 3
            ave_results = np.mean([exp.get_something for exp in project.group('id')])
        """
        pass

class Experiment:

    pass