from hamilton import driver
from hamilton.experimental.h_cache import CachingGraphAdapter

# from hamilton.plugins import h_experiments
from hamilton.function_modifiers import value, parameterize, resolve, ResolveAt
from hamilton.execution.executors import DefaultExecutionManager
from hamilton.execution import executors

import os
import json
from pathlib import Path

from .param import Param, ParamList
from hamilton import settings
from .tracker import ExperimentTracker, Experiment, ExperimentGroup


class Project:

    def __init__(self, name: str, work_dir: str | Path = Path.cwd()):

        self.name = name
        self._root = Path(work_dir).absolute() / name
        self.pre_exec_dir = Path(self.root) / ".pre_exec"
        if not self.pre_exec_dir.exists():
            self.pre_exec_dir.mkdir(parents=True, exist_ok=True)

        self.tracker = ExperimentTracker(base_directory=self.root)

    @property
    def root(self):
        return self._root

    def pre_execute(self, materilizers: list, *modules: list):

        execution_manager = DefaultExecutionManager(
            executors.SynchronousLocalTaskExecutor(),
            executors.MultiThreadingExecutor(20),
        )
        os.chdir(self.pre_exec_dir)
        cache = Path(".cache")
        if not cache.exists():
            cache.mkdir(parents=True, exist_ok=True)
        dr = (
            driver.Builder()
            .with_modules(*modules)
            .enable_dynamic_execution(allow_experimental_mode=True)
            .with_execution_manager(execution_manager)
            .with_adapters(CachingGraphAdapter(str(cache)))
            .build()
        )
        dr.materialize(*materilizers)
        os.chdir(self.root)

    def execute(self, param_list: ParamList, materializers: list, *modules: list):

        execution_manager = DefaultExecutionManager(
            executors.SynchronousLocalTaskExecutor(),
            executors.MultiThreadingExecutor(20),
        )

        parameters = {param.name: {"param": value(param)} for param in param_list}
        for key in parameters:
            parameters[key].update({"name": value(key)})

        @resolve(when=ResolveAt.CONFIG_AVAILABLE, decorate_with=lambda: parameterize(**parameters))
        def execute_exp(name: str, param: Param) -> str:
            # tracker_hook = ExperimentTracker(
            #     experiment_name=name,
            #     base_directory=self.root,
            # )
            run_id = self.tracker.init_experiment(name)
            dr = (
                driver.Builder()
                .with_modules(*modules)
                .enable_dynamic_execution(allow_experimental_mode=True)
                .with_adapters(self.tracker)
                .build()
            )
            dr.materialize(*materializers, inputs=param)
            return run_id

        from molexp import project

        project.execute_exp = execute_exp

        dr = (
            driver.Builder()
            .with_modules(project)
            .enable_dynamic_execution(allow_experimental_mode=True)
            .with_execution_manager(execution_manager)
            .with_config({settings.ENABLE_POWER_USER_MODE: True})
            .build()
        )

        dr.execute(
            final_vars=[name for name in parameters],
        )

    def list(self) -> ExperimentGroup:
        """list all experiment"""
        return ExperimentGroup(
            [
                Experiment.from_cache(json.loads(self.tracker.cache.read(exp_id)))
                for exp_id in self.tracker.cache.keys()
            ]
        )

    def group(self, key: str):
        """group experiments by key, since we need to average the results
        for example:
            input: {'a': 1, 'b': 2, 'id': [1, 2, 3]} # means 3 experiments generated by a=1, b=2
            output: len(project.group('id')) == 3
            ave_results = np.mean([exp.get_something for exp in project.group('id')])
        """
        pass
